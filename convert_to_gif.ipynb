{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "from array2gif import write_gif\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "\tmin_detection_confidence=0.2,\n",
    "\tmin_tracking_confidence=0.2\n",
    ")\n",
    "\n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_6600\\1275729567.py:47: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image = np.zeros((512,512,3), np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you experiencing any pain\n",
      "Can you tell me more about your symptoms\n",
      "A\n",
      "MVI_4405\n",
      "MVI_4393\n",
      "MVI_4394\n",
      "MVI_4396\n",
      "MVI_4397\n",
      "MVI_4400\n",
      "MVI_4401\n",
      "MVI_4402\n",
      "MVI_4403\n",
      "MVI_4404\n"
     ]
    }
   ],
   "source": [
    "video_path = \"G:/SentencesViz/\"\n",
    "video_folder = os.listdir(video_path)\n",
    "\n",
    "for video in video_folder:\n",
    "    filename = video.split(\".\")[0]\n",
    "    print(filename) \n",
    "\n",
    "    video_dir = video_path + video\n",
    "    capture = cv2.VideoCapture(video_dir)\n",
    "    previousTime = 0\n",
    "    currentTime = 0\n",
    "\n",
    "    vid_array = []\n",
    "\n",
    "    while capture.isOpened():\n",
    "\t        # capture frame by frame\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "\t        # resizing the frame for better view\n",
    "            frame = cv2.resize(frame, (800, 600))\n",
    "            \n",
    "            # Converting the from BGR to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t        # Making predictions using holistic model\n",
    "\t        # To improve performance, optionally mark the image as not writeable to\n",
    "\t        # pass by reference.\n",
    "            \n",
    "            image.flags.writeable = False\n",
    "            results = holistic_model.process(image)\n",
    "            image.flags.writeable = True\n",
    "\n",
    "\t        # Converting back the RGB image to BGR\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "\t\t\t# Process pose\n",
    "            pose = list(np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten()) if results.pose_landmarks else list(np.zeros(33*4).flatten())\n",
    "            face = list(np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten()) if results.face_landmarks else list(np.zeros(468*3).flatten())\n",
    "            lh = list(np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten()) if results.left_hand_landmarks else list(np.zeros(21*3).flatten())\n",
    "            rh = list(np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten()) if results.right_hand_landmarks else list(np.zeros(21*3).flatten())\n",
    "            \n",
    "            frame_pose = pose+face+lh+rh\n",
    "            # frame_pose = np.concatenate([pose, face, lh, rh])\n",
    "            # curr_landmarks.append(frame_pose)       \n",
    "            image = np.zeros((512,512,3), np.float)\n",
    "\n",
    "\t        # Drawing the Facial Landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.face_landmarks,\n",
    "\t            mp_holistic.FACEMESH_CONTOURS,\n",
    "\t            mp_drawing.DrawingSpec(\n",
    "\t\t        color=(255,0,255),\n",
    "\t\t        thickness=1,\n",
    "\t\t        circle_radius=0\n",
    "\t        ),\n",
    "\t\n",
    "            mp_drawing.DrawingSpec(\n",
    "\t\t        color=(0,255,255),\n",
    "\t\t        thickness=1,\n",
    "\t\t        circle_radius=0\n",
    "\t        )\n",
    "\t        )\n",
    "\n",
    "\t        # Drawing Right hand Land Marks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.right_hand_landmarks,\n",
    "\t            mp_holistic.HAND_CONNECTIONS\n",
    "\t        )\n",
    "\n",
    "\t        # Drawing Left hand Land Marks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.left_hand_landmarks,\n",
    "\t            mp_holistic.HAND_CONNECTIONS\n",
    "\t        )\n",
    "\n",
    "\t        # Drawing pose Land Marks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.pose_landmarks,\n",
    "\t            mp_holistic.POSE_CONNECTIONS\n",
    "\t        )\n",
    "\t\n",
    "\t        # Calculating the FPS\n",
    "            currentTime = time.time()\n",
    "            fps = 1 / (currentTime-previousTime)\n",
    "            previousTime = currentTime\n",
    "\t\n",
    "\t        # Displaying FPS on the image\n",
    "            # cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "\t        # Display the resulting image\n",
    "            cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "\n",
    "            # image = Image.fromarray(image, 'RGB')\n",
    "            vid_array.append(image)\n",
    "\n",
    "\n",
    "\n",
    "\t        # Enter key 'q' to break the loop\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            # When all the process is done\n",
    "            # Release the capture and destroy all windows\n",
    "    \n",
    "    \n",
    "\n",
    "    vid_array = [Image.fromarray(img.astype(np.uint8)) for img in vid_array]\n",
    "    vid_array[0].save(\"{filename}.gif\".format(filename = filename), save_all=True, append_images=vid_array[1:], duration=50, loop=0)\n",
    "\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'G:/DCIM/Sentences Viz/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mG:/DCIM/Sentences Viz/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m video_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(video_path)\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m video \u001b[39min\u001b[39;00m video_folder:\n\u001b[0;32m      5\u001b[0m     video_id, sign \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mVIDEO_ID\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mSIGN\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'G:/DCIM/Sentences Viz/'"
     ]
    }
   ],
   "source": [
    "video_path = \"G:/DCIM/Sentences Viz/\"\n",
    "video_folder = os.listdir(video_path)\n",
    "\n",
    "for video in video_folder:\n",
    "    video_id, sign = row['VIDEO_ID'], row['SIGN']\n",
    "    video = video_id + \".MOV\"\n",
    "\n",
    "    if video in video_folder: # and count <= max_video_count:\n",
    "        # count += 1\n",
    "\n",
    "        curr_landmarks = []       \n",
    "\n",
    "        video_dir = video_path + video\n",
    "        capture = cv2.VideoCapture(video_dir)\n",
    "\n",
    "        # Initializing current time and precious time for calculating the FPS\n",
    "        previousTime = 0\n",
    "        currentTime = 0\n",
    "\n",
    "        while capture.isOpened():\n",
    "\t        # capture frame by frame\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "\t        # resizing the frame for better view\n",
    "            frame = cv2.resize(frame, (800, 600))\n",
    "            \n",
    "            # Converting the from BGR to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t        # Making predictions using holistic model\n",
    "\t        # To improve performance, optionally mark the image as not writeable to\n",
    "\t        # pass by reference.\n",
    "            \n",
    "            image.flags.writeable = False\n",
    "            results = holistic_model.process(image)\n",
    "            image.flags.writeable = True\n",
    "\n",
    "\t        # Converting back the RGB image to BGR\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "\t\t\t# Process pose\n",
    "            pose = list(np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten()) if results.pose_landmarks else list(np.zeros(33*4).flatten())\n",
    "            face = list(np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten()) if results.face_landmarks else list(np.zeros(468*3).flatten())\n",
    "            lh = list(np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten()) if results.left_hand_landmarks else list(np.zeros(21*3).flatten())\n",
    "            rh = list(np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten()) if results.right_hand_landmarks else list(np.zeros(21*3).flatten())\n",
    "            \n",
    "            frame_pose = pose+face+lh+rh\n",
    "            # frame_pose = np.concatenate([pose, face, lh, rh])\n",
    "            curr_landmarks.append(frame_pose)       \n",
    "            \n",
    "\t\t\t\n",
    "\n",
    "\t        # Drawing the Facial Landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.face_landmarks,\n",
    "\t            mp_holistic.FACEMESH_CONTOURS,\n",
    "\t            mp_drawing.DrawingSpec(\n",
    "\t\t        color=(255,0,255),\n",
    "\t\t        thickness=1,\n",
    "\t\t        circle_radius=1\n",
    "\t        ),\n",
    "\t\n",
    "            mp_drawing.DrawingSpec(\n",
    "\t\t        color=(0,255,255),\n",
    "\t\t        thickness=1,\n",
    "\t\t        circle_radius=1\n",
    "\t        )\n",
    "\t        )\n",
    "\n",
    "\t        # Drawing Right hand Land Marks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.right_hand_landmarks,\n",
    "\t            mp_holistic.HAND_CONNECTIONS\n",
    "\t        )\n",
    "\n",
    "\t        # Drawing Left hand Land Marks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.left_hand_landmarks,\n",
    "\t            mp_holistic.HAND_CONNECTIONS\n",
    "\t        )\n",
    "\n",
    "\t        # Drawing pose Land Marks\n",
    "            mp_drawing.draw_landmarks(\n",
    "\t            image,\n",
    "\t            results.pose_landmarks,\n",
    "\t            mp_holistic.POSE_CONNECTIONS\n",
    "\t        )\n",
    "\t\n",
    "\t        # Calculating the FPS\n",
    "            currentTime = time.time()\n",
    "            fps = 1 / (currentTime-previousTime)\n",
    "            previousTime = currentTime\n",
    "\t\n",
    "\t        # Displaying FPS on the image\n",
    "            cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "\t        # Display the resulting image\n",
    "            cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "\n",
    "\t        # Enter key 'q' to break the loop\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            # When all the process is done\n",
    "            # Release the capture and destroy all windows\n",
    "        \n",
    "        y.append(sign)\n",
    "        X.append(list(np.array(curr_landmarks).flatten()))\n",
    "        \n",
    "\n",
    "        capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(X)\n",
    "        # print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
